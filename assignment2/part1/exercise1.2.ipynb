{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## 1. Properties of CNNs\n",
    "### Question 1.2 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part, we will train a CNN model over the dataset CIFAR-10. This dataset contains 10 classes: plane, car, bird, cat, deer, dog, frog, horse, ship and truck. \n",
    "\n",
    "First, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from CIFAR-10\n",
    "# Define device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to display the first 25 images of a dataset with their corresponding class name and use it over `train_data`. \n",
    "\n",
    "Hint: `class_names = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]`, where the labels are the corresponding index. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_first_few_images(data):\n",
    "    #######################\n",
    "    # PUT YOUR CODE HERE  #\n",
    "    #######################\n",
    "    category_labels = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\",\n",
    "                       \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # go through the first 25 samples\n",
    "    for idx in range(25):\n",
    "        picture, target = data[idx]\n",
    "\n",
    "        # convert from [channels, height, width] to an image format matplotlib understands\n",
    "        image_to_show = picture.permute(1, 2, 0).numpy()\n",
    "\n",
    "        plt.subplot(5, 5, idx + 1)\n",
    "        plt.imshow(image_to_show)\n",
    "        plt.title(category_labels[target])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    #######################\n",
    "    # END OF YOUR CODE    #\n",
    "    #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_first_few_images(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load and train a small CNN model! In the following cells you can check the architecture of the model and the designed function for its training.\n",
    "\n",
    "Note: You shouldn't need Snellius to run it. Either Google Collab or your local computer should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function for training the model\n",
    "def train(model, train_loader, epochs = 10):\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model = CNN().to(device)\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to check the performance of the trained model for the test dataset when rotating the images 0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330 and 360 degrees.\n",
    "\n",
    "For this, you need to first create the function `get_acc_per_angle` that computes the accuracies_per_angle for a given model. You should create a `rotated_test_data` and a `rotated_test_loader`, from which taking the images and labels to give as input to the `inference` function that is provided to you in the following cell. \n",
    "\n",
    "Then, create a `plot` function that plots the accuracy of the model per angle of rotation of the images.   \n",
    "\n",
    "Hint: Check how we used transformations in section a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, images, labels):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_per_angle(model):\n",
    "    angles = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 360]\n",
    "    angle_accuracies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for angle in angles:\n",
    "            #######################\n",
    "            # PUT YOUR CODE HERE  #\n",
    "            #######################\n",
    "            # for each angle I build a version of the CIFAR-10 test set\n",
    "\n",
    "            # where every sample is rotated exactly by this angle\n",
    "            rotation_transform = transforms.Compose([  # type: ignore\n",
    "                transforms.RandomRotation((angle, angle)),  # force fixed rotation\n",
    "                transforms.ToTensor(),                     # convert to tensor\n",
    "            ])\n",
    "\n",
    "            # load the normal test set but with my custom rotation applied\n",
    "            rotated_test_data = datasets.CIFAR10(\n",
    "                root='./data',\n",
    "                train=False,\n",
    "                download=False,\n",
    "                transform=rotation_transform\n",
    "            )\n",
    "\n",
    "            # batching the rotated test set, no shuffle since it's evaluation\n",
    "            rotated_test_loader = torch.utils.data.DataLoader(\n",
    "                rotated_test_data,\n",
    "                batch_size=64,\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            # loop through the whole rotated test split\n",
    "            for images, labels in rotated_test_loader:\n",
    "                # predictions from my inference helper\n",
    "                predictions = inference(model, images, labels)\n",
    "\n",
    "                # count how many are right\n",
    "                correct += (predictions == labels.to(device)).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            # accuracy for this one specific angle\n",
    "            accuracy = correct / total\n",
    "            angle_accuracies.append(accuracy)\n",
    "\n",
    "        \n",
    "            #######################\n",
    "            # END OF YOUR CODE    #\n",
    "            #######################\n",
    "    \n",
    "    return angles, angle_accuracies          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles, angle_accuracies = get_acc_per_angle(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs rotation angle\n",
    "def plot(angles, angle_accuracies):\n",
    "            #######################\n",
    "            # PUT YOUR CODE HERE  #\n",
    "            #######################    \n",
    "\n",
    "        plt.figure(figsize=(7, 5))  # making the figure a bit wider so it's readable\n",
    "\n",
    "        # plotting the angle on x-axis and the measured accuracy on y-axis\n",
    "        plt.plot(angles, angle_accuracies, marker='o')\n",
    "\n",
    "        plt.xlabel(\"Rotation angle (degrees)\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "\n",
    "        # simple title, nothing fancy\n",
    "        plt.title(\"Accuracy vs rotation angle\")\n",
    "\n",
    "        # I like to keep the grid on, otherwise itâ€™s hard to see trends\n",
    "        plt.grid(True)\n",
    "\n",
    "        # make sure every tested angle shows up on the x ticks\n",
    "        plt.xticks(angles)\n",
    "\n",
    "        # accuracy should always be between 0 and 1, so I force the limits\n",
    "        plt.ylim(0, 1.0)\n",
    "\n",
    "        # finally show the plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            #######################\n",
    "            # END OF YOUR CODE    #\n",
    "            #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles, angle_accuracies = get_acc_per_angle(model)\n",
    "plot(angles, angle_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said in the pdf, now we will first train a model with the same architecture as the previous one (this is, you can use the same to initialize the model as before), changing the train dataset so that it contains _random rotations_ of angles of up to 360 degrees. For this, create a new `train_augmentation_transform` to create the train augmented dataset.\n",
    "\n",
    "Hint: Check how we used transformations in Question 1.2 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new train data and loader and visualize it\n",
    "\n",
    "#######################\n",
    "# PUT YOUR CODE HERE  #\n",
    "#######################\n",
    "# for the training data I'm adding some random rotations, basically letting the model\n",
    "# see the images in many different orientations,hoping it helps it generalize better\n",
    "train_augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=(0, 360)),  # full rotation range\n",
    "    transforms.ToTensor(),  # convert the image into a PyTorch tensor\n",
    "])\n",
    "\n",
    "#######################\n",
    "# END OF YOUR CODE    #\n",
    "#######################\n",
    "\n",
    "train_augmented_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_augmentation_transform)\n",
    "train_augmented_loader = torch.utils.data.DataLoader(train_augmented_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "display_first_few_images(train_augmented_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said, we will now initialize the new model and train it over the `train_augmented_loader` you just created. Initialized the new model as we did in the previous question and train it using the `train` function. \n",
    "\n",
    "Note: Again, you shouldn't need Snellius to run it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# PUT YOUR CODE HERE  #\n",
    "#######################\n",
    "\n",
    "model_aug = CNN().to(device)\n",
    "\n",
    "#training model\n",
    "\n",
    "train(model_aug, train_augmented_loader)\n",
    "#######################\n",
    "# END OF YOUR CODE    #\n",
    "#######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, evaluate its performance by running inference over the dataset when rotating the images 0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330 and 360 degrees, and plotting the model's accuracy respect to the angle of rotation of the test dataset. You can use `get_acc_per_angle` and `plot` functions you defined in Question 1.2 (a)!\n",
    "\n",
    "Hint: The test data is the same as in Question 1.2 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# PUT YOUR CODE HERE  #\n",
    "#######################\n",
    "\n",
    "angles_aug, angle_accuracies_aug = get_acc_per_angle(model_aug)\n",
    "\n",
    "#calling plots4\n",
    "\n",
    "plot(angles_aug, angle_accuracies_aug)\n",
    "#######################\n",
    "# END OF YOUR CODE    #\n",
    "#######################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
